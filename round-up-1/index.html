<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="shortcut icon" href="/assets/logo.png" type="image/x-icon" />
    <link rel="stylesheet" href="/style.css" />
    <title>Round Up #1</title>
  </head>
  <body>
    <nav>
      <a href="/"
        ><img src="/assets/logo.png" alt="" title="DECODE" /> DECODE</a
      >
    </nav>
    <main><h1>Round Up #1</h1>
<p>A round up of important tech related news that happened this week. Including Dolly, Databricks open source LLM. Node JS has released an official test runner and more.</p>
<article>
<h6>DECODED</h6>
<h3>Node JS is coming out with built-in testing</h3>
<p><strong>SHORT</strong>: With the newest release of Node v19.9.0, Node is getting a built-in test runner.</p>
<p><strong>LONG</strong>: The test runner API is a new set of built-in tools that will allow you to create tests for your code natively. No more need for Jest, Mocha, or Ava! This will bring Node up with most modern languages (Dart, Rust, GO) and reduce the package size of your code base. It is not a drop-in replacement for other frameworks, so you will need to migrate all of your tests to the new syntax. However, the test runner syntax is very straightforward and takes inspiration from the existing frameworks. This will make transitioning to the built-in test runner much easier.</p>
</article>
<article>
<h6>CLOUD</h6>
<h3>SupaBase Edge Function Update</h3>
<p><strong>SHORT</strong>: SupaBase open sources its edge function runtime allowing you to self-host deno edge functions.</p>
<p><strong>LONG</strong>: Previously when using the <code>supabase functions serve</code> command, you could only serve one edge runtime. This hurt local developer workflow leading to alternative hacks. With the newest update of supabase, you are able to run all functions on the edge runtime using the <code>supabase functions serve</code> command.</p>
</article>
<article>
<h6>HIVEMIND</h6>
<h3>Databricks Releases a Fully Open Source LLM (DOLLY 2.0)</h3>
<p><strong>SHORT</strong>: After releasing <code>dolly 1.0</code> earlier this month, databricks has released an updated version that has been trained on a human-generated instruction set that is licensed for research and commercial use.</p>
<p><strong>LONG</strong>: Databricks crowdsourced 15k human-generated prompts and responses from its over 5,000 employees. Creating a 12 billion parameter LLM that has been trained on high-quality prompts using the EleutherAI Pythia model. To see how they went about creating this LLM you can check out there great blog post about it <a href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" title="Databricks Blog Post">here</a></p>
</article></main>
  </body>
</html>
